\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{fiala2004artag}
\citation{olson2011apriltag}
\citation{bergamasco2011rune}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{I}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Robot about to execute a manipulation task and rearrange the objects on the table. Apriltags are used to find the poses of targeted objects in the scene but ultimately fails to gasp the prism because the orientation of its pose is wrong.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:table_clearing}{{1}{1}{Robot about to execute a manipulation task and rearrange the objects on the table. Apriltags are used to find the poses of targeted objects in the scene but ultimately fails to gasp the prism because the orientation of its pose is wrong.\relax }{figure.caption.1}{}}
\citation{grest2009comparison}
\citation{besl1992method}
\citation{gedik2015rgbd,assa2014robust}
\citation{naimark2002circular}
\citation{bergamasco2011rune}
\citation{rice2006analysing}
\citation{fiala2004artag}
\citation{kato2002artoolkit}
\citation{olson2011apriltag}
\citation{wang2016apriltag}
\citation{hartley2003multiple,zhang2005general}
\citation{dementhon1992exact}
\citation{haralick1994review}
\citation{horaud1989analytic}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Different types of popular fiducial tags. ARToolkit, ARTags, and AprilTags are square tags with black borders. RUNE-tags and Intersense use different circle features as landmarks\relax }}{2}{figure.caption.2}}
\newlabel{fig:tags}{{2}{2}{Different types of popular fiducial tags. ARToolkit, ARTags, and AprilTags are square tags with black borders. RUNE-tags and Intersense use different circle features as landmarks\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {ARToolkit}}}{2}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ARTag}}}{2}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {AprilTag}}}{2}{subfigure.2.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {RUNE-Tag}}}{2}{subfigure.2.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Intersense}}}{2}{subfigure.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}}
\newlabel{sec:related}{{II}{2}{Related Work}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Close up snapshot on the rectangular prism. The physical tag is placed on the surface of the prism but the detected tag is oriented into the prism.\relax }}{2}{figure.caption.3}}
\newlabel{fig:mismatch}{{3}{2}{Close up snapshot on the rectangular prism. The physical tag is placed on the surface of the prism but the detected tag is oriented into the prism.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Challenges}{2}{section.3}}
\newlabel{sec:problem}{{III}{2}{Challenges}{section.3}{}}
\citation{pathak2010uncertainty}
\citation{pathak2010uncertainty}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The ambiguity effect is illustrated with two rendered cubes in the perspective view. The two cubes are rotated such that two faces are interlaced. The red square is a simulated projection of a square tag. The red circular regions denote the region of potential corner detections in a noisy scene. The pose of the red square can converge to either one of the two faces.\relax }}{3}{figure.caption.4}}
\newlabel{fig:cube}{{4}{3}{The ambiguity effect is illustrated with two rendered cubes in the perspective view. The two cubes are rotated such that two faces are interlaced. The red square is a simulated projection of a square tag. The red circular regions denote the region of potential corner detections in a noisy scene. The pose of the red square can converge to either one of the two faces.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Approach}{3}{section.4}}
\newlabel{sec:approach}{{IV}{3}{Approach}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Depth Plane Fitting}{3}{subsection.4.1}}
\newlabel{eq:gaussian_noise}{{1}{3}{Depth Plane Fitting}{subsection.4.1}{}}
\newlabel{eq:gaussian_noise}{{2}{3}{Depth Plane Fitting}{subsection.4.1}{}}
\citation{eggert1997estimating}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Initial Pose Estimation}{4}{subsection.4.2}}
\newlabel{eq:rigid_body}{{3}{4}{Initial Pose Estimation}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Pose Refinement}{4}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An abstract visualization of the optimization constraints. The blue curve is the initial pose estimation obtained from the depth plane. The red curves are the ambiguous poses from the RGB image. We constrained the region of optimization based on how well we fit the depth plane.\relax }}{4}{figure.caption.5}}
\newlabel{fig:optimization}{{5}{4}{An abstract visualization of the optimization constraints. The blue curve is the initial pose estimation obtained from the depth plane. The red curves are the ambiguous poses from the RGB image. We constrained the region of optimization based on how well we fit the depth plane.\relax }{figure.caption.5}{}}
\newlabel{eq:refinement}{{14}{4}{Pose Refinement}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental Results}{4}{section.5}}
\newlabel{sec:res}{{V}{4}{Experimental Results}{figure.caption.7}{}}
\newlabel{fig:exp_setup}{{6a}{5}{Subfigure 6a}{subfigure.6.1}{}}
\newlabel{sub@fig:exp_setup}{{(a)}{a}{Subfigure 6a\relax }{subfigure.6.1}{}}
\newlabel{fig:bimodal}{{6b}{5}{Subfigure 6b}{subfigure.6.2}{}}
\newlabel{sub@fig:bimodal}{{(b)}{b}{Subfigure 6b\relax }{subfigure.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Experimental setup. Groundtruth is computed from a large chessboard where the relative transformation to the tag is known. Each data collection is ran through $1000$ trails and pose errors are measured.\relax }}{5}{figure.caption.6}}
\newlabel{fig:angle_result}{{6}{5}{Experimental setup. Groundtruth is computed from a large chessboard where the relative transformation to the tag is known. Each data collection is ran through $1000$ trails and pose errors are measured.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RGB image at 60$^{\circ }$}}}{5}{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Rotation errors across 1000 trials}}}{5}{subfigure.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Viewing Angle vs Error Percentage under different simulated noise level. The new RGBD based algorithm can resist noise in the RGB image and it vastly outperforms the original algorithm.\relax }}{5}{figure.caption.7}}
\newlabel{fig:viewing_result}{{7}{5}{Viewing Angle vs Error Percentage under different simulated noise level. The new RGBD based algorithm can resist noise in the RGB image and it vastly outperforms the original algorithm.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Distance vs Error Percentage. Data are captured at a $10$ cm increment from $65$ cm to $185$ cm.\relax }}{5}{figure.caption.8}}
\newlabel{fig:distance_result}{{8}{5}{Distance vs Error Percentage. Data are captured at a $10$ cm increment from $65$ cm to $185$ cm.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Viewing Angle}{5}{subsection.5.1}}
\newlabel{fig:illumination_tag}{{\caption@xref {fig:illumination_tag}{ on input line 48}}{6}{Distance}{subfigure.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Apriltags captured by Kinect V2 under different levels of illumination. The RGB sensor dynamically adjust the exposure time to compensate for low lighting. In (a), the image is captured outside of Kinect's adjustable range and the pixels are underexposed. In (b), the long exposure time introduced noticeable noise to the image. \relax }}{6}{figure.caption.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Dark}}}{6}{subfigure.9.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Dim}}}{6}{subfigure.9.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Normal}}}{6}{subfigure.9.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Bright}}}{6}{subfigure.9.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Illumination vs Error Percentage. Data are captured at $65$ cm away from the camera at a $40$ degree angle.\relax }}{6}{figure.caption.10}}
\newlabel{fig:lighting_result}{{10}{6}{Illumination vs Error Percentage. Data are captured at $65$ cm away from the camera at a $40$ degree angle.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Distance}{6}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Average pose errors compared with ar\_track\_alvar package.\relax }}{6}{figure.caption.11}}
\newlabel{fig:alvartrack}{{11}{6}{Average pose errors compared with ar\_track\_alvar package.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Rotation Error}}}{6}{subfigure.11.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Translation Error}}}{6}{subfigure.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Lighting}{6}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Benchmark Against ar\_track\_alvar}{6}{subsection.5.4}}
\bibstyle{ieeetr}
\bibdata{bib/references}
\bibcite{fiala2004artag}{{1}{}{{}}{{}}}
\bibcite{olson2011apriltag}{{2}{}{{}}{{}}}
\bibcite{bergamasco2011rune}{{3}{}{{}}{{}}}
\bibcite{grest2009comparison}{{4}{}{{}}{{}}}
\bibcite{besl1992method}{{5}{}{{}}{{}}}
\bibcite{gedik2015rgbd}{{6}{}{{}}{{}}}
\bibcite{assa2014robust}{{7}{}{{}}{{}}}
\bibcite{naimark2002circular}{{8}{}{{}}{{}}}
\bibcite{rice2006analysing}{{9}{}{{}}{{}}}
\bibcite{kato2002artoolkit}{{10}{}{{}}{{}}}
\bibcite{wang2016apriltag}{{11}{}{{}}{{}}}
\bibcite{hartley2003multiple}{{12}{}{{}}{{}}}
\bibcite{zhang2005general}{{13}{}{{}}{{}}}
\bibcite{dementhon1992exact}{{14}{}{{}}{{}}}
\bibcite{haralick1994review}{{15}{}{{}}{{}}}
\bibcite{horaud1989analytic}{{16}{}{{}}{{}}}
\bibcite{pathak2010uncertainty}{{17}{}{{}}{{}}}
\bibcite{eggert1997estimating}{{18}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{fig:result_compare}{{\caption@xref {fig:result_compare}{ on input line 93}}{7}{Computation Time}{subfigure.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The pose of the Apriltag visualized in RViz computed using the original library VS our RGBD fused method.\relax }}{7}{figure.caption.12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RGB}}}{7}{subfigure.12.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RGBD}}}{7}{subfigure.12.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-E}}Computation Time}{7}{subsection.5.5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}{section.6}}
\newlabel{sec:conclusion}{{VI}{7}{Conclusion}{section.6}{}}
