\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{fiala2004artag}
\citation{olson2011apriltag}
\citation{bergamasco2011rune}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{I}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Robot about to execute a manipulation task and rearrange the objects on the table. Apriltags are used to find the poses of targeted objects in the scene but ultimately fails to gasp the prism because the orientation of its pose is wrong.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:table_clearing}{{1}{1}{Robot about to execute a manipulation task and rearrange the objects on the table. Apriltags are used to find the poses of targeted objects in the scene but ultimately fails to gasp the prism because the orientation of its pose is wrong.\relax }{figure.caption.1}{}}
\citation{grest2009comparison}
\citation{besl1992method}
\citation{gedik2015rgbd,assa2014robust}
\citation{naimark2002circular}
\citation{bergamasco2011rune}
\citation{rice2006analysing}
\citation{fiala2004artag}
\citation{kato2002artoolkit}
\citation{olson2011apriltag}
\citation{wang2016apriltag}
\citation{hartley2003multiple,zhang2005general}
\citation{dementhon1992exact}
\citation{haralick1994review}
\citation{horaud1989analytic}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Different types of popular fiducial tags. ARToolkit, ARTags, and AprilTags are square tags with black borders. RUNE-tags and Intersense use different circle features as landmarks\relax }}{2}{figure.caption.2}}
\newlabel{fig:tags}{{2}{2}{Different types of popular fiducial tags. ARToolkit, ARTags, and AprilTags are square tags with black borders. RUNE-tags and Intersense use different circle features as landmarks\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {ARToolkit}}}{2}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ARTag}}}{2}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {AprilTag}}}{2}{subfigure.2.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {RUNE-Tag}}}{2}{subfigure.2.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Intersense}}}{2}{subfigure.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}}
\newlabel{sec:related}{{II}{2}{Related Work}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The ambiguity effect is illustrated with two rendered cubes in the perspective view. The two cubes are rotated such that two faces are interlaced. The red square is a simulated projection of a square tag. The red circular regions denote the region of potential corner detections in a noisy scene. The pose of the red square can converge to either one of the two faces.\relax }}{2}{figure.caption.3}}
\newlabel{fig:cube}{{3}{2}{The ambiguity effect is illustrated with two rendered cubes in the perspective view. The two cubes are rotated such that two faces are interlaced. The red square is a simulated projection of a square tag. The red circular regions denote the region of potential corner detections in a noisy scene. The pose of the red square can converge to either one of the two faces.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Challenges}{2}{section.3}}
\newlabel{sec:problem}{{III}{2}{Challenges}{section.3}{}}
\citation{pathak2010uncertainty}
\newlabel{fig:simulation_rotation}{{4a}{3}{Subfigure 4a}{subfigure.4.1}{}}
\newlabel{sub@fig:simulation_rotation}{{(a)}{a}{Subfigure 4a\relax }{subfigure.4.1}{}}
\newlabel{fig:simulation_translation}{{4b}{3}{Subfigure 4b}{subfigure.4.2}{}}
\newlabel{sub@fig:simulation_translation}{{(b)}{b}{Subfigure 4b\relax }{subfigure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Simulation results of Apriltag pose estimation under different noise level. In both simulations, four corners are projected onto a rendered image with some noise then computed their poses. In \ref  {fig:simulation_rotation}, corners are projected to the center of the camera 0.8 meters away and rotated from $0^{\circ }$ to $90^{\circ }$. In \ref  {fig:simulation_translation}, the corners are projected at $40^{\circ }$ and moved from 0.6 meters to 1.8 meters. The resulting poses are threshold to calculate the percentage of unacceptable poses.\relax }}{3}{figure.caption.4}}
\newlabel{fig:simulation_results}{{4}{3}{Simulation results of Apriltag pose estimation under different noise level. In both simulations, four corners are projected onto a rendered image with some noise then computed their poses. In \ref {fig:simulation_rotation}, corners are projected to the center of the camera 0.8 meters away and rotated from $0^{\circ }$ to $90^{\circ }$. In \ref {fig:simulation_translation}, the corners are projected at $40^{\circ }$ and moved from 0.6 meters to 1.8 meters. The resulting poses are threshold to calculate the percentage of unacceptable poses.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Incorrect Pose Percentage w.r.t Viewing Angle }}}{3}{subfigure.4.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Incorrect Pose Percentage w.r.t Distance}}}{3}{subfigure.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Approach}{3}{section.4}}
\newlabel{sec:approach}{{IV}{3}{Approach}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Depth Plane Fitting}{3}{subsection.4.1}}
\citation{pathak2010uncertainty}
\citation{eggert1997estimating}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An abstract visualization of the optimization constraints. The blue curve is the initial pose estimation obtained from the depth plane. The red curves are the ambiguous poses from the RGB image. We constrained the region of optimization based on how well we fit the depth plane.\relax }}{4}{figure.caption.5}}
\newlabel{fig:optimization}{{5}{4}{An abstract visualization of the optimization constraints. The blue curve is the initial pose estimation obtained from the depth plane. The red curves are the ambiguous poses from the RGB image. We constrained the region of optimization based on how well we fit the depth plane.\relax }{figure.caption.5}{}}
\newlabel{eq:gaussian_noise}{{1}{4}{Depth Plane Fitting}{subsection.4.1}{}}
\newlabel{eq:gaussian_noise}{{2}{4}{Depth Plane Fitting}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Initial Pose Estimation}{4}{subsection.4.2}}
\newlabel{fig:result_compare}{{\caption@xref {fig:result_compare}{ on input line 64}}{4}{Pose Refinement}{subfigure.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The pose of the Apriltag visualized in RViz computed using the original library VS our RGBD fused method.\relax }}{4}{figure.caption.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RGB}}}{4}{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {RGBD}}}{4}{subfigure.6.2}}
\newlabel{eq:rigid_body}{{3}{4}{Initial Pose Estimation}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Pose Refinement}{4}{subsection.4.3}}
\newlabel{eq:refinement}{{14}{4}{Pose Refinement}{figure.caption.6}{}}
\newlabel{fig:exp_setup}{{7a}{5}{Subfigure 7a}{subfigure.7.1}{}}
\newlabel{sub@fig:exp_setup}{{(a)}{a}{Subfigure 7a\relax }{subfigure.7.1}{}}
\newlabel{fig:bimodal}{{7b}{5}{Subfigure 7b}{subfigure.7.2}{}}
\newlabel{sub@fig:bimodal}{{(b)}{b}{Subfigure 7b\relax }{subfigure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An example of the experimental setup in \ref  {fig:exp_setup}. Groundtruth is computed from a large chessboard where the relative transformation to the tag is known. Each data collection, shown in \ref  {fig:bimodal}, is ran through $1000$ trails and pose errors are measured.\relax }}{5}{figure.caption.7}}
\newlabel{fig:angle_result}{{7}{5}{An example of the experimental setup in \ref {fig:exp_setup}. Groundtruth is computed from a large chessboard where the relative transformation to the tag is known. Each data collection, shown in \ref {fig:bimodal}, is ran through $1000$ trails and pose errors are measured.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RGB image at 60$^{\circ }$}}}{5}{subfigure.7.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Rotation errors across 1000 trials}}}{5}{subfigure.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experimental Results}{5}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Viewing Angle vs Error Percentage under different simulated noise level. The new RGBD based algorithm can resist noise in the RGB image and it vastly outperforms the original algorithm.\relax }}{5}{figure.caption.8}}
\newlabel{fig:viewing_result}{{8}{5}{Viewing Angle vs Error Percentage under different simulated noise level. The new RGBD based algorithm can resist noise in the RGB image and it vastly outperforms the original algorithm.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Viewing Angle}{5}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Distance vs Error Percentage. Data are captured at a $10$ cm increment from $65$ cm to $185$ cm.\relax }}{6}{figure.caption.9}}
\newlabel{fig:distance_result}{{9}{6}{Distance vs Error Percentage. Data are captured at a $10$ cm increment from $65$ cm to $185$ cm.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Distance}{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Lighting}{6}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Apriltags captured by Kinect V2 under different levels of illumination. The RGB sensor dynamically adjust the exposure time to compensate for low lighting. In (a), the image is captured outside of Kinect's adjustable range and the pixels are underexposed. In (b), the long exposure time introduced noticeable noise to the image. \relax }}{6}{figure.caption.10}}
\newlabel{fig:illumination_tag}{{10}{6}{Apriltags captured by Kinect V2 under different levels of illumination. The RGB sensor dynamically adjust the exposure time to compensate for low lighting. In (a), the image is captured outside of Kinect's adjustable range and the pixels are underexposed. In (b), the long exposure time introduced noticeable noise to the image. \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Dark}}}{6}{subfigure.10.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Dim}}}{6}{subfigure.10.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Normal}}}{6}{subfigure.10.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Bright}}}{6}{subfigure.10.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Illumination vs Error Percentage. Data are captured at $65$ cm away from the camera at a $40$ degree angle.\relax }}{6}{figure.caption.11}}
\newlabel{fig:lighting_result}{{11}{6}{Illumination vs Error Percentage. Data are captured at $65$ cm away from the camera at a $40$ degree angle.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Benchmark Against ar\_track\_alvar}{6}{subsection.5.4}}
\bibstyle{ieeetr}
\bibdata{bib/references}
\bibcite{fiala2004artag}{{1}{}{{}}{{}}}
\bibcite{olson2011apriltag}{{2}{}{{}}{{}}}
\bibcite{bergamasco2011rune}{{3}{}{{}}{{}}}
\bibcite{grest2009comparison}{{4}{}{{}}{{}}}
\bibcite{besl1992method}{{5}{}{{}}{{}}}
\bibcite{gedik2015rgbd}{{6}{}{{}}{{}}}
\bibcite{assa2014robust}{{7}{}{{}}{{}}}
\bibcite{naimark2002circular}{{8}{}{{}}{{}}}
\bibcite{rice2006analysing}{{9}{}{{}}{{}}}
\bibcite{kato2002artoolkit}{{10}{}{{}}{{}}}
\bibcite{wang2016apriltag}{{11}{}{{}}{{}}}
\bibcite{hartley2003multiple}{{12}{}{{}}{{}}}
\bibcite{zhang2005general}{{13}{}{{}}{{}}}
\bibcite{dementhon1992exact}{{14}{}{{}}{{}}}
\bibcite{haralick1994review}{{15}{}{{}}{{}}}
\bibcite{horaud1989analytic}{{16}{}{{}}{{}}}
\bibcite{pathak2010uncertainty}{{17}{}{{}}{{}}}
\bibcite{eggert1997estimating}{{18}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Average pose errors compared with ar\_track\_alvar package.\relax }}{7}{figure.caption.12}}
\newlabel{fig:alvartrack}{{12}{7}{Average pose errors compared with ar\_track\_alvar package.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Rotation Error}}}{7}{subfigure.12.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Translation Error}}}{7}{subfigure.12.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-E}}Computation Time}{7}{subsection.5.5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}{section.6}}
\newlabel{sec:conclusion}{{VI}{7}{Conclusion}{section.6}{}}
