% !TEX root = ../main.tex
\section{Introduction}
\label{sec:intro}
Detection and identification using artificial landmarks, known as fiducial markers, has long been used in augmented reality and computer vision applications. Over the last decade, there have been numerous marker systems, such as ARTags, Apriltags, and Rune Tags, designed to improve detection encoding precision. However, these systems are not robust enough to be used reliability in many robotic applications.

Compared to markerless detection algorithms, these fiducial marker methods are simpler and more consistent. There has been significant effort in improving the detection speed and encoding accuracy *OF WHAT*. They yield great results for computer vision tasks that require high detection accuracy like camera calibrations and 3D reconstruction. Furthermore, they have gained popularity in the robotic community for having unique characteristics of high detection rates and numerous encoding schemes. For example, Apriltags are commonly used to test SLAM systems, or finding ground truth for objects in manipulation and motion planning tasks as shown in Figure \ref{fig:table_clearing}. 

Despite all the improvements, obtaining accurate pose estimations from these *UNCLEAR* tags remain a challenge. This is especially important for robotic applications because small errors can cause large system failures as the errors propagate and amplify through the system. Currently, these systems *UNCLEAR* yield good results under well conditioned or rendered environments, but this does not translate to ill-conditioned settings. For instance, when Apriltags are used with low resolution cameras or harsh lighting conditions, the system often produces poses with tremendous rotational errors as shown in Figure \ref{fig:mismatch}. In fact, we observe that the localization accuracy of this system *WHAT SYSTEM* perform significantly worse at particular viewing angles, or when there is noise in the scene. This is a difficult problem because RGB sensors are sensitive to lighting, and current fiducial systems are not designed to take advantage of other sensors commonly available on robots.

We present two main contributions in this paper. First, we conducted an in-depth analysis on the effect of various noises on the pose estimation process. In particular, the noise in RGB images creates a perspective ambiguity problem that makes the pose estimation challenging without additional information. Second, we describe a novel method that takes advantage of the RGBD sensors that are commonly available on most robotic systems to accurately estimate the pose from a single tag under noisy conditions in real time. In the core of the algorithm, we recognize that RGB and depth sensors work optimally under different conditions. Therefore, their strength can be combined meaningfully to improve the localization accuracy robust to illumination *MAYBE UNCLEAR*. There are a few key features to this algorithm: 
\begin{itemize}
\item This method is highly robust to noise in the scene. It can obtain accurate poses suitable for a wide range robotic applications.   
\item It is easily generalizable to most fiducial tag designs.
\item *UNCLEAR*It performs at worse at least as good as using only RGB images.
\item It has very small computation overhead, and can be ran in real time. 
\end{itemize}

This paper also presents empirical results demonstrating the successful performance of the algorithm on captured data from a humanoid robot. Our implementation of the algorithm is based off of the Apriltag detection pipeline and it is integrated with ROS. 

\begin{figure}
\includegraphics[width=\columnwidth, height=120px]{figs/table_clearing_rgb_small} \\
\includegraphics[width=\columnwidth, height=120px]{figs/table_clearing_depth}
\label{fig:table_clearing}
\caption{Apriltag used to localize objects in mainpulation tasks}
\end{figure}