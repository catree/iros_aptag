% !TEX root = ../main.tex
\section{Introduction}
\label{sec:intro}
Detection and identification using artificial landmarks has long been used in augmented reality and computer vision applications. Over the last decade, there has been numerous marker systems, such as ARTags, Apriltags, and Rune Tags, designed to improve detection encoding precision. However, these systems are not robust enough to be used reliability in many robotic applications.

Compared to markerless detection algorithms, these fiducial marker methods are simpler and more consistent. There has been significant effort in improving the detection speed and encoding accuracy. As the result, they have yield great results for computer vision tasks that require high detection accuracy like camera calibrations, 3D reconstruction. Furthermore, they have gained popularity in the robotic community for having unique characteristics of high detection rates and numerous encoding schemes. For example, ARTags are commonly used to test SLAM systems or finding ground truth for objects in manipulation and motion planning tasks as shown in Figure \ref{fig:table_clearing}. 

Despite all the improvements, obtaining accurate pose estimations from these tags remain a challenge. This is especially important for robotic applications because small errors can cause large system failures as the errors propagate and amplifies through the system. Currently, these systems yield good results under well conditioned or rendered environments, but this does not translate to ill-conditioned settings. For instances, when Apriltags are used with low resolution camera or harsh lighting conditions, the system often produce poses with tremendous rotational errors as shown in Figure \ref{fig:mismatch}. In fact, we observe that the localization accuracy of this system perform significantly worse at difficult viewing angles or when there are noise in the scene. This is a difficult problem because RGB sensors are sensitive to lighting and current fiducial systems are not designed to take advantage of other sensors commonly available on robots.

We present two main contributions in this paper. First, we conducted an in-depth analysis on the effect of various noises on the pose estimation process. In particular, the noise in RGB images creates a perspective ambiguity problem that makes the pose estimation challenging without additional information. Second, we describe a novel method that takes advantage of the RGBD sensors that are commonly available on most robotic systems to accurately estimate the pose from a single tag under noisy conditions in real time. In the core of the algorithm, we recognize that RGB and depth sensors work optimally under different conditions. Therefore, their strength can be combined meaningfully to improve the localization accuracy robust to illumination. There are few key features to this algorithm: 
\begin{itemize}
\item This method is highly robust to noise in the scene. It can obtain accurate poses suitable for a wide range robotic applications.   
\item It is easily generalizable to most fiducial tags designs.
\item It performs at worse at least as good as using only RGB images.
\item It has very small computation overhead and can be ran in real time. 
\end{itemize}

This paper also presents empirical results demonstrating the the successful performance of the algorithm on captured data from an humanoid robot. Our implementation of the algorithm is based off of the Apriltag detection pipeline and it is integrated with ROS. 

\begin{figure}
\includegraphics[width=\columnwidth, height=120px]{figs/table_clearing_rgb_small} \\
\includegraphics[width=\columnwidth, height=120px]{figs/table_clearing_depth}
\label{fig:table_clearing}
\caption{Apriltag used to localize objects in mainpulation tasks}
\end{figure}